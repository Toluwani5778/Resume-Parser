{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062014a5",
   "metadata": {},
   "source": [
    "### Display the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5beffe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx2pdf import convert\n",
    "from IPython.display import display, IFrame\n",
    "import os\n",
    "import PyPDF2 as pdf\n",
    "from pyresparser import ResumeParser\n",
    "import spacy\n",
    "import tempfile\n",
    "from docx2pdf import convert\n",
    "import re\n",
    "import nltk\n",
    "from spacy.matcher import Matcher\n",
    "import constants as cs\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0becf6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pdf(pdf_path):\n",
    "    # Convert absolute path to relative path\n",
    "    notebook_dir = os.getcwd()  # Get the current working directory where the notebook is located\n",
    "    relative_path = os.path.relpath(pdf_path, notebook_dir)\n",
    "    # Display the PDF using an iframe\n",
    "    display(IFrame(relative_path, width=800, height=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7dfde",
   "metadata": {},
   "source": [
    "Parsing Structure: Identifies key sections of the resume like contact information, education, work experience, skills, etc., using techniques like keyword matching, regular expressions, or machine learning models.\n",
    "\n",
    "Data Extraction: Extracts specific information within each section:\n",
    "\n",
    "Contact: Name, email address, phone number, location (optional).\n",
    "\n",
    "Education: School name, degree name, graduation year, location (optional), relevant coursework (optional).\n",
    "\n",
    "Work Experience: Company name, job title, employment dates, location (optional), key responsibilities and achievements (bullet points).\n",
    "\n",
    "Skills: Technical skills, soft skills, keywords.\n",
    "Additional Sections: Certifications, awards, projects (optional), depending on the parser's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "640ff8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"..\\..\\..\\Apprenticeship\\New Apprenticeship\\Resume.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x29ba27f11e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted from the file:\n",
      "TOLUWANI C. OLUKANNI  \n",
      "Northfield, VT 05663  | +1 (267) 423 -3529  | tolukann5778@gmail.com  | linkedin.com/in/toluwani -olukanni  | https://github.com/Toluwani5778  \n",
      "Education  \n",
      "Norwich University, Northfield, VT                May 2025  \n",
      "Bachelor of Science in Electrical and Computer Engineering  \n",
      "Minors: Mathematics and Computer Science                         GPA 3.9 6 \n",
      "Relevant courses and topics: Embedded Systems, Circuit Design and Analysis, Electronics and  Electrical \n",
      "Components, Programming for Microcontrollers, Signal Processing, Fundamentals of Digital Design  \n",
      " \n",
      "Relevant Experience  \n",
      "Information Operations /Cybersecurity  Subject Matter Expert  \n",
      "Norwich University Applied Research Institute             January  2024 – Present  \n",
      "Norwich University, Northfield, VT  \n",
      "• Collaborate with the Software Development Team to integrate ML models seamlessly into the CI/CD \n",
      "pipeline.  \n",
      "• Assist in the execution of assigned duties and tasks to support the development of secure and robust \n",
      "software solutions.  \n",
      "• Find social media references in text using Natural Language Processing techniques.  \n",
      "• Collaborate with data scientists and engineers to streamline the deployment of models into production \n",
      "environments, utilizing containerization and orchestration tools.  \n",
      " \n",
      "President /Founder , Norwich University Artificial Intelligence Club                          \n",
      "Norwich University, Northfield, VT       September 2023 – Present  \n",
      "• Established the club and created its organizational framework, assigning committed officers to \n",
      "essential roles.  \n",
      "• Initiate and orchestrate a sequence of events, workshops, and seminars centered around Artificial \n",
      "Intelligence.  \n",
      "• Coordinate  with club members to execute AI projects, fostering practical learning opportunities.  \n",
      "• Lead conversations on contemporary AI trends and their practical use, elevating members' \n",
      "understanding of AI's capabilities.  \n",
      " \n",
      "Research Apprentice, AY 23 -24 Apprentice Grant  \n",
      "Undergraduate Research Program  \n",
      "Norwich University, Northfield, VT                        August 2023 – Present  \n",
      "• Collaborate with a team to tackle the challenge of comprehending various pulses in time distributions \n",
      "by developing a central mathematical model.  \n",
      "• Enhance  the raw data processing program to improve event classification accuracy, reducing the \n",
      "misclassification rate for double pulses from 5% to less than 1%.  \n",
      "• Spearhead the mathematical modeling of time distribution shapes, with the goal of establishing a \n",
      "comprehensive model that consistently links various pulse regions.  \n",
      "• Actively participate in testing and fine -tuning algorithms and models, conducting extensive data \n",
      "collection and analysis to refine hypotheses and validate predictions.  \n",
      "• Play a key role in experimental data collection across diverse operating conditions, encompassing \n",
      "varying light intensities and laser sources, including 405 nm and 535 nm, to support model testing and \n",
      "refinement.  \n",
      " \n",
      "Research Team Lead, Summer AI Research Fellows  \n",
      "Artificial Intelligence Center  \n",
      "Norwich University, Northfield, VT                     May 2023 – August 2023  \n",
      "• Offered personalized mentorship and guidance, enabling team members to excel in research projects \n",
      "and expand their AI expertise.  \n",
      "• Collaborated closely with esteemed professors, contributing to cutting -edge AI initiatives and projects.  \n",
      "• Attained invaluable insights into diverse AI applications and explored innovative approaches for \n",
      "optimizing medical diagnosis through advanced machine learning techniques.  \n",
      "• Published a research paper titled \"Advanced Misinformation Detection: A Bi -LSTM Model Optimized by \n",
      "Genetic Algorithms\" in the Electronics journal by MDPI . \n",
      "• Presented the Image Classification project at the Norwich Summer of Digital Transformation \n",
      "Colloquium, effectively communicating technical concepts to a diverse audience, including Norwich \n",
      "officials, faculty, and AI specialists.  Technical Skills  \n",
      "• Designed circuits and prototypes using SolidWorks, TinkerCAD, NI Multisim, LTspice, Arduino IDE, Intel \n",
      "Quartus, and Code Composer Studio.  \n",
      "• Conducted circuit analysis, specializing in schematic design and troubleshooting, working with Op \n",
      "Amps, 555 Timers, and various tools.  \n",
      "• Proficient in programming languages: QBasic, Python, C++, MATLAB, C, Assembly, Verilog HDL, and \n",
      "Sage.  \n",
      "• Skilled in software tools: MS Word, MS Excel, MS PowerPoint, Adobe Photoshop, and Corel Draw.  \n",
      "• Extensive knowledge in Machine Learning (ML) with experience in ML Classification, Sentiment \n",
      "Analysis, Computer Vision, and more.  \n",
      "• Acquired hands -on experience in metal finishing techniques, including shining and polishing metal \n",
      "surfaces, utilizing various tools such as files, Dremel tools, and buffing wheels to achieve a high -quality \n",
      "finish.  \n",
      " \n",
      "Projects & Work Portfolio  \n",
      "• Inductive Cross -Sectional Area Sensor for Bore Tube Measurement: A collaborative project with \n",
      "peers involving the principle of mutual induction between a sensing coil and a virtual coil to measure \n",
      "the distance between them.  \n",
      "Expected Completion:  December 2025  \n",
      "• Search and Rescue AI -enabled drones: A collaborative project utilizing Python to develop intelligent \n",
      "drones with enhanced search and rescue capabilities, actively participating in integrating AI algorithms \n",
      "and drone technology to address autonomous navigation, obstacle avoidance, and real -time data \n",
      "analysis challenges.  \n",
      "• Enhancing Lung Cancer Diagnosis with Regularized CNNs for Histopathological Image \n",
      "Classification: The purpose of this project was to explore multiple methods of regularization to \n",
      "minimize overfitting in Convolutional Neural Networks and increase validation accuracy and \n",
      "generalization of the data.  \n",
      "• 8x8 LED Matrix MAX7219 Display controlled by Arduino via Bluetooth: An interactive project \n",
      "featuring an 8x8 LED Matrix MAX7219 display, controlled wirelessly by Arduino through Bluetooth \n",
      "connectivity. Explored the use of HC -05 Bluetooth Module, Arduino MEGA, and Application for inputs.  \n",
      " \n",
      "Publication  \n",
      "Multidisciplinary Digital Publishing Institute ( MDPI) : \n",
      "A. Al Bataineh, V. Reyes, T. Olukanni, M. Khalaf, A. Vibho, and R. Pedyuk, “Advanced Misinformation \n",
      "Detection: A Bi -LSTM Model Optimized by Genetic Algorithms,” Electronics , vol. 12, no. 15, p. 3250, \n",
      "Jul. 2023, doi: https://doi.org/10.3390/electronics12153250.  \n",
      " \n",
      "Honors & Awards  \n",
      "• Member of Tau Beta Pi – The Engineering Honor Society           November  2023  \n",
      "• Quest Fest                September 2023  \n",
      "Award presented by Associate Provost for Research  \n",
      "People’s Choice Award, presented by President of Norwich University        \n",
      "• University Scholar (GPA 3.60 – 3.99)                     August 2023  \n",
      "• Secretary of IEEE - Eta Kappa Nu [Electrical Engineering Honors Society]         April 2023  \n",
      "• Norwich Engineers’ Society, Peter E. Kyle Award            April 2023  \n",
      "• First -Year Student Award, University Scholar – 4.0 GPA Award                  August 2022  \n",
      " \n",
      "Certificates  \n",
      "• CRLA International Tutor Training Program Certification       August 2023  \n",
      "• Google Cloud Skills Boost:                June 2023  \n",
      "Attention Mechanism, Create Image Captioning Models, Encoder -Decoder Architecture, Generative AI \n",
      "Fundamentals, Introduction to Generative AI, Introduction to Image Generation, Introduction to Large \n",
      "Language  \n",
      "• Kaggle:                   May 2023  \n",
      "Pandas, Intro to Machine Learning, Feature Engineering, Intro to Deep Learning  \n"
     ]
    }
   ],
   "source": [
    "def read_text_from_file(file_path):\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    if file_extension.lower() == '.pdf':\n",
    "        display_pdf(file_path)\n",
    "        return read_text_from_pdf(file_path)\n",
    "    elif file_extension.lower() == '.docx':\n",
    "        pdf_path = convert_docx_to_pdf(file_path)\n",
    "        if pdf_path:\n",
    "            display_pdf(pdf_path)\n",
    "            return read_text_from_pdf(pdf_path)\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Unsupported file format. Supported formats are PDF and DOCX.\")\n",
    "        return None\n",
    "\n",
    "def read_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            reader = pdf.PdfFileReader(f)\n",
    "            text = \"\"\n",
    "            for page_num in range(reader.numPages):\n",
    "                text += reader.getPage(page_num).extractText()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading text from PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_docx_to_pdf(docx_path):\n",
    "    try:\n",
    "        # Convert DOCX to PDF\n",
    "        pdf_path = tempfile.mktemp(suffix='.pdf')\n",
    "        convert(docx_path, pdf_path)\n",
    "        return pdf_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting DOCX to PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "# file_path = \"Resume Examples\\Creative teaching resume.docx\" # Replace with the path to your file\n",
    "file_path = r\"C:\\Users\\hotpr\\OneDrive - Norwich University\\Apprenticeship\\New Apprenticeship\\Resume.pdf\"\n",
    "text = read_text_from_file(file_path)\n",
    "if text:\n",
    "    print(\"Text extracted from the file:\")\n",
    "    print(text)\n",
    "else:\n",
    "    print(\"Failed to extract text from the file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ae25a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolukann5778@gmail.com\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_email(text):\n",
    "    '''\n",
    "    Helper function to extract email id from text\n",
    "\n",
    "    :param text: plain text extracted from resume file\n",
    "    '''\n",
    "    email = re.findall(r\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", text)\n",
    "    if email:\n",
    "        try:\n",
    "            return email[0].split()[0].strip(';')\n",
    "        except IndexError:\n",
    "            return None\n",
    "        \n",
    "print(extract_email(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f16aacc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "Full Name: John D. Doe\n",
      "First Name: John\n",
      "Middle Initial: None\n",
      "Last Name: None\n",
      "\n",
      "None\n",
      "Full Name: John Doe\n",
      "First Name: John\n",
      "Middle Initial: None\n",
      "Last Name: None\n",
      "\n",
      "None\n",
      "Full Name: John\n",
      "First Name: John\n",
      "Middle Initial: None\n",
      "Last Name: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_name(full_name):\n",
    "    # Regular expression patterns for different name formats\n",
    "    patterns = [\n",
    "        # First name, middle initial, last name\n",
    "        r'^([A-Z][a-z]+)\\s+([A-Z])\\.\\s+([A-Z][a-z]+)$',\n",
    "        # First name, last name\n",
    "        r'^([A-Z][a-z]+)\\s+([A-Z][a-z]+)$',\n",
    "        # First name\n",
    "        r'^([A-Z][a-z]+)$'\n",
    "    ]\n",
    "    \n",
    "    # Iterate through each pattern and attempt to match\n",
    "    for pattern in patterns:\n",
    "        match = re.match(pattern, full_name)\n",
    "        if match:\n",
    "            # Extract the parts based on the matched pattern\n",
    "            if len(match.groups()) == 3:\n",
    "                return match.group(1), match.group(2), match.group(3)\n",
    "            elif len(match.groups()) == 2:\n",
    "                return match.group(1), None, match.group(2)\n",
    "            else:\n",
    "                return match.group(1), None, None\n",
    "    \n",
    "    # If no match found, return None\n",
    "    return None, None, None\n",
    "\n",
    "# Example usage\n",
    "name_formats = [\n",
    "    \"John D. Doe\",\n",
    "    \"John Doe\",\n",
    "    \"John\"\n",
    "]\n",
    "\n",
    "for name in name_formats:\n",
    "    print(extract_name(name)[1])\n",
    "    print(\"Full Name:\", name)\n",
    "    print(\"First Name:\", first_name)\n",
    "    print(\"Middle Initial:\", middle_initial)\n",
    "    print(\"Last Name:\", last_name)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b1addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bachelor of Science in Electrical and Computer Engineering']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def extract_education_from_resume(text):\n",
    "#     education = []\n",
    "\n",
    "#     # List of education keywords to match against\n",
    "#     education_keywords = ['Bsc', 'B. Pharmacy', 'B Pharmacy', 'Msc', 'M. Pharmacy', 'Ph.D', 'Bachelor', 'Master']\n",
    "\n",
    "#     for keyword in education_keywords:\n",
    "#         pattern = r\"(?i)\\b{}\\b\".format(re.escape(keyword))\n",
    "#         match = re.search(pattern, text)\n",
    "#         if match:\n",
    "#             education.append(match.group())\n",
    "\n",
    "#     return education\n",
    "\n",
    "def extract_education_from_resume(text):\n",
    "    education = []\n",
    "\n",
    "    # Use regex pattern to find education information\n",
    "    pattern = r\"(?i)(?:Bsc|\\bB\\.\\w+|\\bM\\.\\w+|\\bPh\\.D\\.\\w+|\\bBachelor(?:'s)?|\\bMaster(?:'s)?|\\bPh\\.D)\\s(?:\\w+\\s)*\\w+\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    for match in matches:\n",
    "        education.append(match.strip())\n",
    "\n",
    "    return education\n",
    "\n",
    "extract_education_from_resume(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374fba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+1 (267) 423 -3529']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def remove_newlines(text):\n",
    "  \"\"\"Removes all newline characters (`\\n`) from a string.\"\"\"\n",
    "  return text.replace('\\n', '')\n",
    "\n",
    "def extract_phone_numbers(text):\n",
    "    '''\n",
    "    Function to extract phone numbers from text\n",
    "\n",
    "    :param text: plain text containing phone numbers\n",
    "    :return: list of phone numbers found in the text\n",
    "    '''\n",
    "    pattern = re.compile(r'(?<!\\n)(\\+?\\d{0,3}\\s?[-\\.\\(\\)]?\\s?\\(?\\d{3}\\)?\\s?[-\\.\\(\\)]?\\s?\\d{3}\\s?[-\\.\\(\\)]?\\s?\\d{4})')\n",
    "\n",
    "    # Find all matches of the pattern in the text\n",
    "    matches = re.findall(pattern, text)\n",
    "    clean_matches = [remove_newlines(match).lstrip() for match in matches]\n",
    "    # Return the list of phone numbers found\n",
    "    return clean_matches\n",
    "\n",
    "\n",
    "print(extract_phone_numbers(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7010284b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOLUWANI C.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp_text = nlp(text)\n",
    "def extract_name(nlp_text):\n",
    "    '''\n",
    "    Helper function to extract name from spacy nlp text\n",
    "\n",
    "    :param nlp_text: object of `spacy.tokens.doc.Doc`\n",
    "    :param matcher: object of `spacy.matcher.Matcher`\n",
    "    :return: string of full name\n",
    "    '''\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    for pattern in cs.NAME_PATTERN:\n",
    "        matcher.add('NAME', [pattern])\n",
    "    matches = matcher(nlp_text)\n",
    "\n",
    "    for _, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        if 'name' not in span.text.lower():\n",
    "            return span.text\n",
    "        \n",
    "print(extract_name(nlp_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf71585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def detect_date_format(date_str):\n",
    "    '''\n",
    "    Detects the format of the input date string.\n",
    "\n",
    "    :param date_str: Input date string\n",
    "    :return: Detected date format\n",
    "    '''\n",
    "    formats = [\n",
    "        ('%b %Y', 'Month YYYY'),\n",
    "        ('%Y-%m-%d', 'YYYY-MM-DD'),  # ISO 8601 format\n",
    "        ('%m/%d/%Y', 'MM/DD/YYYY'),  # US format\n",
    "        ('%d-%m-%Y', 'DD-MM-YYYY'),  # European/African format\n",
    "        ('%B %dst, %Y', 'Month DDst, YYYY'),  # Full month name with ordinal day\n",
    "        ('%B %dnd, %Y', 'Month DDnd, YYYY'),  # Full month name with ordinal day\n",
    "        ('%B %drd, %Y', 'Month DDrd, YYYY'),  # Full month name with ordinal day\n",
    "        ('%B %dth, %Y', 'Month DDth, YYYY')   # Full month name with ordinal day\n",
    "    ]\n",
    "\n",
    "    for date_format, format_name in formats:\n",
    "        try:\n",
    "            datetime.strptime(date_str, date_format)\n",
    "            return format_name\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90eab4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_experience(experience_list):\n",
    "    '''\n",
    "    Wrapper function to extract total months of experience from a resume\n",
    "\n",
    "    :param experience_list: list of experience text extracted\n",
    "    :return: total months of experience\n",
    "    '''\n",
    "    exp_ = []\n",
    "    for line in experience_list:\n",
    "        experience = re.search(\n",
    "            r'(?P<fmonth>\\w+.\\d+)\\s*(\\D|to)\\s*(?P<smonth>\\w+.\\d+|present)',\n",
    "            line,\n",
    "            re.I\n",
    "        )\n",
    "        if experience:\n",
    "            exp_.append(experience.groups())\n",
    "    total_exp = sum(\n",
    "        [get_number_of_months_from_dates(i[0], i[2]) for i in exp_]\n",
    "    )\n",
    "    total_experience_in_months = total_exp\n",
    "    return total_experience_in_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbe6cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months of experience: 35\n"
     ]
    }
   ],
   "source": [
    "def get_number_of_months_from_dates(date1, date2):\n",
    "    '''\n",
    "    Helper function to extract total months of experience from a resume\n",
    "\n",
    "    :param date1: Starting date\n",
    "    :param date2: Ending date\n",
    "    :return: months of experience from date1 to date2\n",
    "    '''\n",
    "    months_of_experience = 0  # Default value\n",
    "    \n",
    "    if detect_date_format(date1) == 'YYYY-MM-DD':\n",
    "        if date2.lower() == 'present':\n",
    "            date2 = datetime.now().strftime('%Y-%m-%d')\n",
    "        try:\n",
    "            start_date = datetime.strptime(str(date1), '%Y-%m-%d')\n",
    "            end_date = datetime.strptime(str(date2), '%Y-%m-%d')\n",
    "            months_of_experience = (end_date.year - start_date.year) * 12 + (\n",
    "                end_date.month - start_date.month)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "\n",
    "    elif detect_date_format(date1) == 'MM/DD/YYYY':\n",
    "        if date2.lower() == 'present':\n",
    "            date2 = datetime.now().strftime('%m/%d/%Y')\n",
    "        try:\n",
    "            start_date = datetime.strptime(str(date1), '%m/%d/%Y')\n",
    "            end_date = datetime.strptime(str(date2), '%m/%d/%Y')\n",
    "            months_of_experience = (end_date.year - start_date.year) * 12 + (\n",
    "                end_date.month - start_date.month)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "\n",
    "    elif detect_date_format(date1) == 'DD-MM-YYYY':\n",
    "        if date2.lower() == 'present':\n",
    "            date2 = datetime.now().strftime('%d-%m-%Y')\n",
    "        try:\n",
    "            start_date = datetime.strptime(str(date1), '%d-%m-%Y')\n",
    "            end_date = datetime.strptime(str(date2), '%d-%m-%Y')\n",
    "            months_of_experience = (end_date.year - start_date.year) * 12 + (\n",
    "                end_date.month - start_date.month)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "\n",
    "    elif detect_date_format(date1) == 'Month DDst, YYYY':\n",
    "        if date2.lower() == 'present':\n",
    "            date2 = datetime.now().strftime('%B %dst, %Y')\n",
    "        try:\n",
    "            start_date = datetime.strptime(str(date1), '%B %dst, %Y')\n",
    "            end_date = datetime.strptime(str(date2), '%B %dst, %Y')\n",
    "            months_of_experience = (end_date.year - start_date.year) * 12 + (\n",
    "                end_date.month - start_date.month)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    elif detect_date_format(date1) == 'Month DDnd, YYYY':\n",
    "        if date2.lower() == 'present':\n",
    "            date2 = datetime.now().strftime('%B %dnd, %Y')\n",
    "        try:\n",
    "            start_date = datetime.strptime(str(date1), '%B %dnd, %Y')\n",
    "            end_date = datetime.strptime(str(date2), '%B %dnd, %Y')\n",
    "            months_of_experience = (end_date.year - start_date.year) * 12 + (\n",
    "                end_date.month - start_date.month)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    elif detect_date_format(date1) == 'Month DDrd, YYYY':\n",
    "        if date2.lower() == 'present':\n",
    "            date2 = datetime.now().strftime('%B %drd, %Y')\n",
    "        try:\n",
    "            start_date = datetime.strptime(str(date1), '%B %drd, %Y')\n",
    "            end_date = datetime.strptime(str(date2), '%B %drd, %Y')\n",
    "            months_of_experience = (end_date.year - start_date.year) * 12 + (\n",
    "                end_date.month - start_date.month)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    elif detect_date_format(date1) == 'Month DDth, YYYY':\n",
    "        if date2.lower() == 'present':\n",
    "            date2 = datetime.now().strftime('%B %dth, %Y')\n",
    "        try:\n",
    "            start_date = datetime.strptime(str(date1), '%B %dth, %Y')\n",
    "            end_date = datetime.strptime(str(date2), '%B %dth, %Y')\n",
    "            months_of_experience = (end_date.year - start_date.year) * 12 + (\n",
    "                end_date.month - start_date.month)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    elif detect_date_format(date1) == 'Month YYYY':\n",
    "        \n",
    "        if date2.lower() == 'present':\n",
    "            date2 = datetime.now().strftime('%b %Y')\n",
    "        try:\n",
    "            if len(date1.split()[0]) > 3:\n",
    "                date1 = date1.split()\n",
    "                date1 = date1[0][:3] + ' ' + date1[1]\n",
    "            if len(date2.split()[0]) > 3:\n",
    "                date2 = date2.split()\n",
    "                date2 = date2[0][:3] + ' ' + date2[1]\n",
    "        except IndexError:\n",
    "            return 0\n",
    "        try:\n",
    "            date1 = datetime.strptime(str(date1), '%b %Y')\n",
    "            date2 = datetime.strptime(str(date2), '%b %Y')\n",
    "            months_of_experience = relativedelta(date2, date1)\n",
    "            months_of_experience = (months_of_experience.years * 12 +\n",
    "                                    months_of_experience.months)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    else:\n",
    "        try:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            return \"Can't calculate\"\n",
    "\n",
    "    return months_of_experience\n",
    "\n",
    "\n",
    "date1 = 'Jan 2019'  # Starting date\n",
    "date2 = 'Dec 2021'  # Ending date\n",
    "months_of_experience = get_number_of_months_from_dates(date1, date2)\n",
    "print(\"Months of experience:\", months_of_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06442be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analysis', 'C++', 'Adobe', 'Algorithms', 'Excel', 'Collaborative', 'Design', 'Adobe photoshop', 'C', 'Matrix', 'Training', 'Programming', 'Modeling', 'Cloud', 'Mathematics', 'Python', 'International', 'Assembly', 'Pandas', 'Science', 'Research projects', 'Data', 'Distribution', 'Solidworks', 'Electrical', 'Troubleshooting', 'Software', 'Medical', 'Circuits', 'Matlab', 'Interactive', 'Machine learning', 'Technology', 'Architecture', 'Deep learning', 'Publishing', 'Accuracy', 'Electronics', 'Experimental', 'Photoshop', 'Research', 'Powerpoint', 'Word', 'Technical', 'Testing', 'Computer', 'Ms excel', 'Ai', 'Engineering', 'Corel draw', 'Certification', 'Operations', 'Languages']\n"
     ]
    }
   ],
   "source": [
    "def extract_skills(nlp_text, skills_file=None):\n",
    "    '''\n",
    "    Helper function to extract skills from spacy nlp text\n",
    "\n",
    "    :param nlp_text: object of `spacy.tokens.doc.Doc`\n",
    "    :param noun_chunks: noun chunks extracted from nlp text\n",
    "    :return: list of skills extracted\n",
    "    '''\n",
    "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
    "    noun_chunks = nlp_text.noun_chunks\n",
    "    if not skills_file:\n",
    "        data = pd.read_csv(\n",
    "            os.path.join(os.getcwd(), 'skills.csv')\n",
    "        )\n",
    "    else:\n",
    "        data = pd.read_csv(skills_file)\n",
    "    skills = list(data.columns.values)\n",
    "    skillset = []\n",
    "    # check for one-grams\n",
    "    for token in tokens:\n",
    "        if token.lower() in skills:\n",
    "            skillset.append(token)\n",
    "\n",
    "    # check for bi-grams and tri-grams\n",
    "    for token in noun_chunks:\n",
    "        token = token.text.lower().strip()\n",
    "        if token in skills:\n",
    "            skillset.append(token)\n",
    "    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
    "\n",
    "print(extract_skills(nlp_text))\n",
    "\n",
    "## Edit the skills csv to make sure no rubbish skills is considered \n",
    "# investigate if time management is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ff3270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bachelor', 'MS']\n"
     ]
    }
   ],
   "source": [
    "def extract_education(nlp_text):\n",
    "    '''\n",
    "    Helper function to extract education from spacy nlp text\n",
    "\n",
    "    :param nlp_text: object of `spacy.tokens.doc.Doc`\n",
    "    :return: tuple of education degree and year if year if found\n",
    "             else only returns education degree\n",
    "    '''\n",
    "    edu = {}\n",
    "    # Extract education degree\n",
    "    try:\n",
    "        for token in nlp_text:\n",
    "            token_text = token.text.strip()\n",
    "            token_text = re.sub(r'[?|$|.|!|,]', r'', token_text)\n",
    "            if token_text.upper() in cs.EDUCATION and token_text not in cs.STOPWORDS:\n",
    "                # Concatenate current token with next token if available\n",
    "                next_token = nlp_text[token.i + 1].text if token.i + 1 < len(nlp_text) else ''\n",
    "                edu[token_text] = token.text + next_token\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    # Extract year\n",
    "    education = []\n",
    "    for key in edu.keys():\n",
    "        year = re.search(re.compile(cs.YEAR), edu[key])\n",
    "        if year:\n",
    "            education.append((key, ''.join(year.group(0))))\n",
    "        else:\n",
    "            education.append(key)\n",
    "    return education\n",
    "\n",
    "print(extract_education(nlp_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89c4622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Information Operations']\n"
     ]
    }
   ],
   "source": [
    "def extract_experience(resume_text):\n",
    "    '''\n",
    "    Helper function to extract experience from resume text\n",
    "\n",
    "    :param resume_text: Plain resume text\n",
    "    :return: list of experience\n",
    "    '''\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # word tokenization\n",
    "    word_tokens = nltk.word_tokenize(resume_text)\n",
    "\n",
    "    # remove stop words and lemmatize\n",
    "    filtered_sentence = [\n",
    "            w for w in word_tokens if w not\n",
    "            in cs.STOPWORDS and wordnet_lemmatizer.lemmatize(w)\n",
    "            not in cs.STOPWORDS\n",
    "        ]\n",
    "    sent = nltk.pos_tag(filtered_sentence)\n",
    "\n",
    "    # parse regex\n",
    "    cp = nltk.RegexpParser('P: {<NNP>+}')\n",
    "    cse = cp.parse(sent)\n",
    "\n",
    "    # for i in cs.subtrees(filter=lambda x: x.label() == 'P'):\n",
    "    #     print(i)\n",
    "\n",
    "    test = []\n",
    "\n",
    "    for vp in list(\n",
    "        cse.subtrees(filter=lambda x: x.label() == 'P')\n",
    "    ):\n",
    "        test.append(\" \".join([\n",
    "            i[0] for i in vp.leaves()\n",
    "            if len(vp.leaves()) >= 2])\n",
    "        )\n",
    "\n",
    "    # Search the word 'experience' in the chunk and\n",
    "    # then print out the text after it\n",
    "    x = [\n",
    "        x[x.lower().index('experience') + 10:]\n",
    "        for i, x in enumerate(test)\n",
    "        if x and 'experience' in x.lower()\n",
    "    ]\n",
    "    return x\n",
    "\n",
    "print(extract_experience(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198e083c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'education': ['Norwich University, Northfield, VT                May 2025',\n",
       "  'Bachelor of Science in Electrical and Computer Engineering',\n",
       "  'Minors: Mathematics and Computer Science                         GPA 3.9 6',\n",
       "  'Relevant courses and topics: Embedded Systems, Circuit Design and Analysis, Electronics and  Electrical',\n",
       "  'Components, Programming for Microcontrollers, Signal Processing, Fundamentals of Digital Design'],\n",
       " 'experience': ['surfaces, utilizing various tools such as files, Dremel tools, and buffing wheels to achieve a high -quality',\n",
       "  'finish.',\n",
       "  'Projects & Work Portfolio',\n",
       "  '• Inductive Cross -Sectional Area Sensor for Bore Tube Measurement: A collaborative project with',\n",
       "  'peers involving the principle of mutual induction between a sensing coil and a virtual coil to measure',\n",
       "  'the distance between them.',\n",
       "  'Expected Completion:  December 2025',\n",
       "  '• Search and Rescue AI -enabled drones: A collaborative project utilizing Python to develop intelligent',\n",
       "  'drones with enhanced search and rescue capabilities, actively participating in integrating AI algorithms',\n",
       "  'and drone technology to address autonomous navigation, obstacle avoidance, and real -time data',\n",
       "  'analysis challenges.',\n",
       "  '• Enhancing Lung Cancer Diagnosis with Regularized CNNs for Histopathological Image',\n",
       "  'Classification: The purpose of this project was to explore multiple methods of regularization to',\n",
       "  'minimize overfitting in Convolutional Neural Networks and increase validation accuracy and',\n",
       "  'generalization of the data.',\n",
       "  '• 8x8 LED Matrix MAX7219 Display controlled by Arduino via Bluetooth: An interactive project',\n",
       "  'featuring an 8x8 LED Matrix MAX7219 display, controlled wirelessly by Arduino through Bluetooth',\n",
       "  'connectivity. Explored the use of HC -05 Bluetooth Module, Arduino MEGA, and Application for inputs.',\n",
       "  'Publication',\n",
       "  'Multidisciplinary Digital Publishing Institute ( MDPI) :',\n",
       "  'A. Al Bataineh, V. Reyes, T. Olukanni, M. Khalaf, A. Vibho, and R. Pedyuk, “Advanced Misinformation',\n",
       "  'Detection: A Bi -LSTM Model Optimized by Genetic Algorithms,” Electronics , vol. 12, no. 15, p. 3250,',\n",
       "  'Jul. 2023, doi: https://doi.org/10.3390/electronics12153250.',\n",
       "  'Honors & Awards',\n",
       "  '• Member of Tau Beta Pi – The Engineering Honor Society           November  2023',\n",
       "  '• Quest Fest                September 2023',\n",
       "  'Award presented by Associate Provost for Research',\n",
       "  'People’s Choice Award, presented by President of Norwich University',\n",
       "  '• University Scholar (GPA 3.60 – 3.99)                     August 2023',\n",
       "  '• Secretary of IEEE - Eta Kappa Nu [Electrical Engineering Honors Society]         April 2023',\n",
       "  '• Norwich Engineers’ Society, Peter E. Kyle Award            April 2023',\n",
       "  '• First -Year Student Award, University Scholar – 4.0 GPA Award                  August 2022',\n",
       "  'Certificates',\n",
       "  '• CRLA International Tutor Training Program Certification       August 2023'],\n",
       " 'skills': ['Attention Mechanism, Create Image Captioning Models, Encoder -Decoder Architecture, Generative AI',\n",
       "  'Fundamentals, Introduction to Generative AI, Introduction to Image Generation, Introduction to Large',\n",
       "  'Language',\n",
       "  '• Kaggle:                   May 2023',\n",
       "  'Pandas, Intro to Machine Learning, Feature Engineering, Intro to Deep Learning']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_entity_sections_professional(text):\n",
    "    '''\n",
    "    Helper function to extract all the raw text from sections of\n",
    "    resume specifically for professionals\n",
    "\n",
    "    :param text: Raw text of resume\n",
    "    :return: dictionary of entities\n",
    "    '''\n",
    "    text_split = [i.strip() for i in text.split('\\n')]\n",
    "    entities = {}\n",
    "    key = False\n",
    "    for phrase in text_split:\n",
    "        if len(phrase) == 1:\n",
    "            p_key = phrase\n",
    "        else:\n",
    "            p_key = set(phrase.lower().split()) \\\n",
    "                    & set(cs.RESUME_SECTIONS_PROFESSIONAL)\n",
    "        try:\n",
    "            p_key = list(p_key)[0]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        if p_key in cs.RESUME_SECTIONS_PROFESSIONAL:\n",
    "            entities[p_key] = []\n",
    "            key = p_key\n",
    "        elif key and phrase.strip():\n",
    "            entities[key].append(phrase)\n",
    "    return entities\n",
    "\n",
    "extract_entity_sections_professional(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc25ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'education': ['Norwich University, Northfield, VT                May 2025',\n",
       "  'Bachelor of Science in Electrical and Computer Engineering',\n",
       "  'Minors: Mathematics and Computer Science                         GPA 3.9 6',\n",
       "  'Relevant courses and topics: Embedded Systems, Circuit Design and Analysis, Electronics and  Electrical',\n",
       "  'Components, Programming for Microcontrollers, Signal Processing, Fundamentals of Digital Design'],\n",
       " 'experience': ['surfaces, utilizing various tools such as files, Dremel tools, and buffing wheels to achieve a high -quality',\n",
       "  'finish.'],\n",
       " 'projects': ['• Inductive Cross -Sectional Area Sensor for Bore Tube Measurement: A collaborative project with',\n",
       "  'peers involving the principle of mutual induction between a sensing coil and a virtual coil to measure',\n",
       "  'the distance between them.',\n",
       "  'Expected Completion:  December 2025',\n",
       "  '• Search and Rescue AI -enabled drones: A collaborative project utilizing Python to develop intelligent',\n",
       "  'drones with enhanced search and rescue capabilities, actively participating in integrating AI algorithms',\n",
       "  'and drone technology to address autonomous navigation, obstacle avoidance, and real -time data',\n",
       "  'analysis challenges.',\n",
       "  '• Enhancing Lung Cancer Diagnosis with Regularized CNNs for Histopathological Image',\n",
       "  'Classification: The purpose of this project was to explore multiple methods of regularization to',\n",
       "  'minimize overfitting in Convolutional Neural Networks and increase validation accuracy and',\n",
       "  'generalization of the data.',\n",
       "  '• 8x8 LED Matrix MAX7219 Display controlled by Arduino via Bluetooth: An interactive project',\n",
       "  'featuring an 8x8 LED Matrix MAX7219 display, controlled wirelessly by Arduino through Bluetooth',\n",
       "  'connectivity. Explored the use of HC -05 Bluetooth Module, Arduino MEGA, and Application for inputs.'],\n",
       " 'publication': ['Multidisciplinary Digital Publishing Institute ( MDPI) :',\n",
       "  'A. Al Bataineh, V. Reyes, T. Olukanni, M. Khalaf, A. Vibho, and R. Pedyuk, “Advanced Misinformation',\n",
       "  'Detection: A Bi -LSTM Model Optimized by Genetic Algorithms,” Electronics , vol. 12, no. 15, p. 3250,',\n",
       "  'Jul. 2023, doi: https://doi.org/10.3390/electronics12153250.'],\n",
       " 'honors': ['• Norwich Engineers’ Society, Peter E. Kyle Award            April 2023',\n",
       "  '• First -Year Student Award, University Scholar – 4.0 GPA Award                  August 2022'],\n",
       " 'certificates': ['• CRLA International Tutor Training Program Certification       August 2023',\n",
       "  '• Google Cloud Skills Boost:                June 2023',\n",
       "  'Attention Mechanism, Create Image Captioning Models, Encoder -Decoder Architecture, Generative AI',\n",
       "  'Fundamentals, Introduction to Generative AI, Introduction to Image Generation, Introduction to Large',\n",
       "  'Language',\n",
       "  '• Kaggle:                   May 2023',\n",
       "  'Pandas, Intro to Machine Learning, Feature Engineering, Intro to Deep Learning']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_entity_sections(text):\n",
    "    '''\n",
    "    Helper function to extract all the raw text from sections of\n",
    "    resume specifically for graduates and undergraduates\n",
    "\n",
    "    :param text: Raw text of resume\n",
    "    :return: dictionary of entities\n",
    "    '''\n",
    "    text_split = [i.strip() for i in text.split('\\n')]\n",
    "    entities = {}\n",
    "    key = False\n",
    "    for phrase in text_split:\n",
    "        if len(phrase) == 1:\n",
    "            p_key = phrase\n",
    "        else:\n",
    "            p_key = set(phrase.lower().split()) \\\n",
    "                    & set(cs.RESUME_SECTIONS)\n",
    "        try:\n",
    "            p_key = list(p_key)[0]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        if p_key in cs.RESUME_SECTIONS:\n",
    "            entities[p_key] = []\n",
    "            key = p_key\n",
    "        elif key and phrase.strip():\n",
    "            entities[key].append(phrase)\n",
    "\n",
    "    return entities\n",
    "\n",
    "extract_entity_sections(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9acf52c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['• Inductive Cross -Sectional Area Sensor for Bore Tube Measurement: A collaborative project with', 'peers involving the principle of mutual induction between a sensing coil and a virtual coil to measure', 'the distance between them.', 'Expected Completion:  December 2025', '• Search and Rescue AI -enabled drones: A collaborative project utilizing Python to develop intelligent', 'drones with enhanced search and rescue capabilities, actively participating in integrating AI algorithms', 'and drone technology to address autonomous navigation, obstacle avoidance, and real -time data', 'analysis challenges.', '• Enhancing Lung Cancer Diagnosis with Regularized CNNs for Histopathological Image', 'Classification: The purpose of this project was to explore multiple methods of regularization to', 'minimize overfitting in Convolutional Neural Networks and increase validation accuracy and', 'generalization of the data.', '• 8x8 LED Matrix MAX7219 Display controlled by Arduino via Bluetooth: An interactive project', 'featuring an 8x8 LED Matrix MAX7219 display, controlled wirelessly by Arduino through Bluetooth', 'connectivity. Explored the use of HC -05 Bluetooth Module, Arduino MEGA, and Application for inputs.']\n"
     ]
    }
   ],
   "source": [
    "sections = extract_entity_sections(text)\n",
    "if \"projects\" in sections:\n",
    "    print(sections[\"projects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8723f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
